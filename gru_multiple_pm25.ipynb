{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data size: 17520\n",
      "Train data size: 10512\n",
      "Valid data size: 3504\n",
      "Test data size: 3504\n",
      "Model: \"sequential_193\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_227 (GRU)                (None, 300)               272700    \n",
      "_________________________________________________________________\n",
      "dense_193 (Dense)            (None, 24)                7224      \n",
      "=================================================================\n",
      "Total params: 279,924\n",
      "Trainable params: 279,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "146/146 [==============================] - 3s 9ms/step - loss: 0.0068 - val_loss: 0.0019\n",
      "Epoch 2/100\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 0.0060 - val_loss: 0.0026\n",
      "Epoch 3/100\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0059 - val_loss: 0.0017\n",
      "Epoch 4/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0057 - val_loss: 0.0019\n",
      "Epoch 5/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 6/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0054 - val_loss: 0.0019\n",
      "Epoch 7/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0052 - val_loss: 0.0021\n",
      "Epoch 8/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0052 - val_loss: 0.0020\n",
      "Epoch 9/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0050 - val_loss: 0.0024\n",
      "Epoch 10/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0047 - val_loss: 0.0021\n",
      "Epoch 11/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0046 - val_loss: 0.0020\n",
      "Epoch 12/100\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0047 - val_loss: 0.0020\n",
      "Epoch 13/100\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0045 - val_loss: 0.0023\n",
      "Epoch 14/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 15/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0044 - val_loss: 0.0022\n",
      "Epoch 16/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 17/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0042 - val_loss: 0.0019\n",
      "Epoch 18/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 19/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 20/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 21/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 22/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 23/100\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 24/100\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 25/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 26/100\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 27/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 28/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 29/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 30/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 31/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 32/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0039 - val_loss: 0.0018\n",
      "Epoch 33/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 34/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 35/100\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 36/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 37/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 38/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 39/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 40/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 41/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 42/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 43/100\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 44/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 45/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 46/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 47/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 48/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 49/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 50/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 51/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 52/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 53/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0039 - val_loss: 0.0024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johnny\\AppData\\Local\\Temp\\ipykernel_47812\\3948869189.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  evaluate['diff'] = evaluate['prediction']-evaluate['PM25']\n",
      "C:\\Users\\Johnny\\AppData\\Local\\Temp\\ipykernel_47812\\3948869189.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  evaluate['diff'] = evaluate['diff'].abs();\n",
      "C:\\Users\\Johnny\\AppData\\Local\\Temp\\ipykernel_47812\\3948869189.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  evaluate['mape'] = evaluate['diff']/evaluate['PM25'];\n",
      "C:\\Users\\Johnny\\AppData\\Local\\Temp\\ipykernel_47812\\3948869189.py:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  evaluate['mape']=abs((evaluate['PM25']-evaluate['prediction'])/evaluate['PM25'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE 28079008 - 60.44161062920692\n",
      "MAE 28079008 - 0.05149841077438395\n",
      "MSE 28079008 - 0.005092000582520427\n",
      "RMSE 28079008 - 0.0713582551813063\n",
      "duration 28079008 38.16134858131409\n",
      "Total data size: 17520\n",
      "Train data size: 10512\n",
      "Valid data size: 3504\n",
      "Test data size: 3504\n",
      "Model: \"sequential_194\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_228 (GRU)                (None, 300)               272700    \n",
      "_________________________________________________________________\n",
      "dense_194 (Dense)            (None, 24)                7224      \n",
      "=================================================================\n",
      "Total params: 279,924\n",
      "Trainable params: 279,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "146/146 [==============================] - 2s 8ms/step - loss: 0.0064 - val_loss: 0.0022\n",
      "Epoch 2/100\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0020\n",
      "Epoch 3/100\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0021\n",
      "Epoch 4/100\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0023\n",
      "Epoch 5/100\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0054 - val_loss: 0.0022\n",
      "Epoch 6/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0055 - val_loss: 0.0023\n",
      "Epoch 7/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0055 - val_loss: 0.0026\n",
      "Epoch 8/100\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0053 - val_loss: 0.0029\n",
      "Epoch 9/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0052 - val_loss: 0.0024\n",
      "Epoch 10/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0050 - val_loss: 0.0028\n",
      "Epoch 11/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0050 - val_loss: 0.0028\n",
      "Epoch 12/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0050 - val_loss: 0.0027\n",
      "Epoch 13/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 14/100\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 15/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 16/100\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 17/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 18/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 19/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Epoch 20/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 21/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 22/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 23/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0044 - val_loss: 0.0034\n",
      "Epoch 24/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 25/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 26/100\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 27/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 28/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 29/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 30/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 31/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 32/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 33/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 34/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0045 - val_loss: 0.0045\n",
      "Epoch 35/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 36/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 37/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 38/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0044 - val_loss: 0.0033\n",
      "Epoch 39/100\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 40/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 41/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 42/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 43/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 44/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 45/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 46/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0043 - val_loss: 0.0039\n",
      "Epoch 47/100\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 48/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 49/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 50/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 51/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 52/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0042 - val_loss: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johnny\\AppData\\Local\\Temp\\ipykernel_47812\\3948869189.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  evaluate['diff'] = evaluate['prediction']-evaluate['PM25']\n",
      "C:\\Users\\Johnny\\AppData\\Local\\Temp\\ipykernel_47812\\3948869189.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  evaluate['diff'] = evaluate['diff'].abs();\n",
      "C:\\Users\\Johnny\\AppData\\Local\\Temp\\ipykernel_47812\\3948869189.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  evaluate['mape'] = evaluate['diff']/evaluate['PM25'];\n",
      "C:\\Users\\Johnny\\AppData\\Local\\Temp\\ipykernel_47812\\3948869189.py:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  evaluate['mape']=abs((evaluate['PM25']-evaluate['prediction'])/evaluate['PM25'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE 28079047 - 57.91910311803691\n",
      "MAE 28079047 - 0.05615625634741269\n",
      "MSE 28079047 - 0.006990325288420076\n",
      "RMSE 28079047 - 0.08360816520185141\n",
      "duration 28079047 37.33326721191406\n",
      "Total data size: 17520\n",
      "Train data size: 10512\n",
      "Valid data size: 3504\n",
      "Test data size: 3504\n",
      "Model: \"sequential_195\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_229 (GRU)                (None, 300)               272700    \n",
      "_________________________________________________________________\n",
      "dense_195 (Dense)            (None, 24)                7224      \n",
      "=================================================================\n",
      "Total params: 279,924\n",
      "Trainable params: 279,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "146/146 [==============================] - 2s 6ms/step - loss: 0.0069 - val_loss: 0.0043\n",
      "Epoch 2/100\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 3/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 4/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 5/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 6/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 7/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 8/100\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 9/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0043 - val_loss: 0.0058\n",
      "Epoch 10/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0041 - val_loss: 0.0073\n",
      "Epoch 11/100\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0040 - val_loss: 0.0076\n",
      "Epoch 12/100\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0085\n",
      "Epoch 13/100\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.0039 - val_loss: 0.0080\n",
      "Epoch 14/100\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.0038 - val_loss: 0.0069\n",
      "Epoch 15/100\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.0039 - val_loss: 0.0060\n",
      "Epoch 16/100\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.0038 - val_loss: 0.0072\n",
      "Epoch 17/100\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.0038 - val_loss: 0.0065\n",
      "Epoch 18/100\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.0038 - val_loss: 0.0073\n",
      "Epoch 19/100\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.0037 - val_loss: 0.0073\n",
      "Epoch 20/100\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0037 - val_loss: 0.0081\n",
      "Epoch 21/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0037 - val_loss: 0.0076\n",
      "Epoch 22/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0038 - val_loss: 0.0083\n",
      "Epoch 23/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0036 - val_loss: 0.0074\n",
      "Epoch 24/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0037 - val_loss: 0.0080\n",
      "Epoch 25/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0037 - val_loss: 0.0069\n",
      "Epoch 26/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0037 - val_loss: 0.0070\n",
      "Epoch 27/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0037 - val_loss: 0.0076\n",
      "Epoch 28/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0037 - val_loss: 0.0081\n",
      "Epoch 29/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0036 - val_loss: 0.0076\n",
      "Epoch 30/100\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0036 - val_loss: 0.0068\n",
      "Epoch 31/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0037 - val_loss: 0.0070\n",
      "Epoch 32/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0037 - val_loss: 0.0075\n",
      "Epoch 33/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0036 - val_loss: 0.0078\n",
      "Epoch 34/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0036 - val_loss: 0.0070\n",
      "Epoch 35/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0037 - val_loss: 0.0076\n",
      "Epoch 36/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0037 - val_loss: 0.0075\n",
      "Epoch 37/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0037 - val_loss: 0.0078\n",
      "Epoch 38/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0037 - val_loss: 0.0069\n",
      "Epoch 39/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0037 - val_loss: 0.0086\n",
      "Epoch 40/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0035 - val_loss: 0.0073\n",
      "Epoch 41/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0035 - val_loss: 0.0070\n",
      "Epoch 42/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0036 - val_loss: 0.0071\n",
      "Epoch 43/100\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0036 - val_loss: 0.0075\n",
      "Epoch 44/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0036 - val_loss: 0.0086\n",
      "Epoch 45/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0036 - val_loss: 0.0071\n",
      "Epoch 46/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0036 - val_loss: 0.0099\n",
      "Epoch 47/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0037 - val_loss: 0.0072\n",
      "Epoch 48/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0035 - val_loss: 0.0081\n",
      "Epoch 49/100\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0036 - val_loss: 0.0078\n",
      "Epoch 50/100\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0037 - val_loss: 0.0074\n",
      "Epoch 51/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0035 - val_loss: 0.0076\n",
      "Epoch 52/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0036 - val_loss: 0.0094\n",
      "Epoch 53/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0036 - val_loss: 0.0070\n",
      "Epoch 54/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0035 - val_loss: 0.0088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johnny\\AppData\\Local\\Temp\\ipykernel_47812\\3948869189.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  evaluate['diff'] = evaluate['prediction']-evaluate['PM25']\n",
      "C:\\Users\\Johnny\\AppData\\Local\\Temp\\ipykernel_47812\\3948869189.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  evaluate['diff'] = evaluate['diff'].abs();\n",
      "C:\\Users\\Johnny\\AppData\\Local\\Temp\\ipykernel_47812\\3948869189.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  evaluate['mape'] = evaluate['diff']/evaluate['PM25'];\n",
      "C:\\Users\\Johnny\\AppData\\Local\\Temp\\ipykernel_47812\\3948869189.py:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  evaluate['mape']=abs((evaluate['PM25']-evaluate['prediction'])/evaluate['PM25'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE 28079026 - 26.456575267858224\n",
      "MAE 28079026 - 0.055236044310909976\n",
      "MSE 28079026 - 0.00577207710761613\n",
      "RMSE 28079026 - 0.07597418711388843\n",
      "duration 28079026 40.407100677490234\n",
      "Total data size: 17520\n",
      "Train data size: 10512\n",
      "Valid data size: 3504\n",
      "Test data size: 3504\n",
      "Model: \"sequential_196\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_230 (GRU)                (None, 300)               272700    \n",
      "_________________________________________________________________\n",
      "dense_196 (Dense)            (None, 24)                7224      \n",
      "=================================================================\n",
      "Total params: 279,924\n",
      "Trainable params: 279,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "146/146 [==============================] - 2s 6ms/step - loss: 0.0064 - val_loss: 0.0044\n",
      "Epoch 2/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 3/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 4/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 5/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 6/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 7/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 8/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 9/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 10/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 11/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0044 - val_loss: 0.0063\n",
      "Epoch 12/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0042 - val_loss: 0.0061\n",
      "Epoch 13/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0042 - val_loss: 0.0056\n",
      "Epoch 14/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0040 - val_loss: 0.0071\n",
      "Epoch 15/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0040 - val_loss: 0.0054\n",
      "Epoch 16/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0038 - val_loss: 0.0053\n",
      "Epoch 17/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0039 - val_loss: 0.0078\n",
      "Epoch 18/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0039 - val_loss: 0.0066\n",
      "Epoch 19/100\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0039 - val_loss: 0.0075\n",
      "Epoch 20/100\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.0039 - val_loss: 0.0078\n",
      "Epoch 21/100\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 0.0037 - val_loss: 0.0057\n",
      "Epoch 22/100\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 0.0040 - val_loss: 0.0063\n",
      "Epoch 23/100\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.0038 - val_loss: 0.0066\n",
      "Epoch 24/100\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.0039 - val_loss: 0.0064\n",
      "Epoch 25/100\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.0037 - val_loss: 0.0072\n",
      "Epoch 26/100\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.0038 - val_loss: 0.0062\n",
      "Epoch 27/100\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.0038 - val_loss: 0.0065\n",
      "Epoch 28/100\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.0038 - val_loss: 0.0070\n",
      "Epoch 29/100\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0039 - val_loss: 0.0066\n",
      "Epoch 30/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0038 - val_loss: 0.0063\n",
      "Epoch 31/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0038 - val_loss: 0.0072\n",
      "Epoch 32/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0038 - val_loss: 0.0074\n",
      "Epoch 33/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0037 - val_loss: 0.0069\n",
      "Epoch 34/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0039 - val_loss: 0.0068\n",
      "Epoch 35/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0038 - val_loss: 0.0069\n",
      "Epoch 36/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0039 - val_loss: 0.0060\n",
      "Epoch 37/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0038 - val_loss: 0.0079\n",
      "Epoch 38/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0039 - val_loss: 0.0064\n",
      "Epoch 39/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0036 - val_loss: 0.0066\n",
      "Epoch 40/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0038 - val_loss: 0.0062\n",
      "Epoch 41/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0038 - val_loss: 0.0082\n",
      "Epoch 42/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0038 - val_loss: 0.0058\n",
      "Epoch 43/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0038 - val_loss: 0.0070\n",
      "Epoch 44/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0037 - val_loss: 0.0079\n",
      "Epoch 45/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0039 - val_loss: 0.0064\n",
      "Epoch 46/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0036 - val_loss: 0.0062\n",
      "Epoch 47/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0036 - val_loss: 0.0060\n",
      "Epoch 48/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0038 - val_loss: 0.0067\n",
      "Epoch 49/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0037 - val_loss: 0.0063\n",
      "Epoch 50/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0037 - val_loss: 0.0071\n",
      "Epoch 51/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0035 - val_loss: 0.0066\n",
      "Epoch 52/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0036 - val_loss: 0.0069\n",
      "Epoch 53/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0036 - val_loss: 0.0060\n",
      "Epoch 54/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0037 - val_loss: 0.0063\n",
      "Epoch 55/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0037 - val_loss: 0.0067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johnny\\AppData\\Local\\Temp\\ipykernel_47812\\3948869189.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  evaluate['diff'] = evaluate['prediction']-evaluate['PM25']\n",
      "C:\\Users\\Johnny\\AppData\\Local\\Temp\\ipykernel_47812\\3948869189.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  evaluate['diff'] = evaluate['diff'].abs();\n",
      "C:\\Users\\Johnny\\AppData\\Local\\Temp\\ipykernel_47812\\3948869189.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  evaluate['mape'] = evaluate['diff']/evaluate['PM25'];\n",
      "C:\\Users\\Johnny\\AppData\\Local\\Temp\\ipykernel_47812\\3948869189.py:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  evaluate['mape']=abs((evaluate['PM25']-evaluate['prediction'])/evaluate['PM25'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE 28079006 - 45.50269720621774\n",
      "MAE 28079006 - 0.05195342674437734\n",
      "MSE 28079006 - 0.0053500285262020825\n",
      "RMSE 28079006 - 0.07314388919248198\n",
      "duration 28079006 40.1088285446167\n",
      "Total data size: 17520\n",
      "Train data size: 10512\n",
      "Valid data size: 3504\n",
      "Test data size: 3504\n",
      "Model: \"sequential_197\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_231 (GRU)                (None, 300)               272700    \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 24)                7224      \n",
      "=================================================================\n",
      "Total params: 279,924\n",
      "Trainable params: 279,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "146/146 [==============================] - 2s 6ms/step - loss: 0.0133 - val_loss: 0.0042\n",
      "Epoch 2/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0114 - val_loss: 0.0045\n",
      "Epoch 3/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0112 - val_loss: 0.0046\n",
      "Epoch 4/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0110 - val_loss: 0.0047\n",
      "Epoch 5/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0105 - val_loss: 0.0046\n",
      "Epoch 6/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0107 - val_loss: 0.0048\n",
      "Epoch 7/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0103 - val_loss: 0.0063\n",
      "Epoch 8/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0102 - val_loss: 0.0054\n",
      "Epoch 9/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0097 - val_loss: 0.0067\n",
      "Epoch 10/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0096 - val_loss: 0.0062\n",
      "Epoch 11/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0093 - val_loss: 0.0067\n",
      "Epoch 12/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0091 - val_loss: 0.0070\n",
      "Epoch 13/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0090 - val_loss: 0.0079\n",
      "Epoch 14/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0090 - val_loss: 0.0070\n",
      "Epoch 15/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0088 - val_loss: 0.0060\n",
      "Epoch 16/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0085 - val_loss: 0.0075\n",
      "Epoch 17/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0087 - val_loss: 0.0073\n",
      "Epoch 18/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0088 - val_loss: 0.0077\n",
      "Epoch 19/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0083 - val_loss: 0.0079\n",
      "Epoch 20/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0086 - val_loss: 0.0077\n",
      "Epoch 21/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0084 - val_loss: 0.0062\n",
      "Epoch 22/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0086 - val_loss: 0.0086\n",
      "Epoch 23/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0084 - val_loss: 0.0070\n",
      "Epoch 24/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 25/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0085 - val_loss: 0.0091\n",
      "Epoch 26/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0082 - val_loss: 0.0090\n",
      "Epoch 27/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0083 - val_loss: 0.0084\n",
      "Epoch 28/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0081 - val_loss: 0.0080\n",
      "Epoch 29/100\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0086 - val_loss: 0.0083\n",
      "Epoch 30/100\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.0083 - val_loss: 0.0078\n",
      "Epoch 31/100\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.0079 - val_loss: 0.0076\n",
      "Epoch 32/100\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 0.0082 - val_loss: 0.0071\n",
      "Epoch 33/100\n",
      "146/146 [==============================] - 1s 7ms/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 34/100\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0082 - val_loss: 0.0077\n",
      "Epoch 35/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0080 - val_loss: 0.0075\n",
      "Epoch 36/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0084 - val_loss: 0.0076\n",
      "Epoch 37/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0078 - val_loss: 0.0085\n",
      "Epoch 38/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0082 - val_loss: 0.0081\n",
      "Epoch 39/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0084 - val_loss: 0.0090\n",
      "Epoch 40/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0081 - val_loss: 0.0074\n",
      "Epoch 41/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0080 - val_loss: 0.0065\n",
      "Epoch 42/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0081 - val_loss: 0.0068\n",
      "Epoch 43/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0077 - val_loss: 0.0067\n",
      "Epoch 44/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0079 - val_loss: 0.0082\n",
      "Epoch 45/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0080 - val_loss: 0.0061\n",
      "Epoch 46/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0083 - val_loss: 0.0064\n",
      "Epoch 47/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0078 - val_loss: 0.0083\n",
      "Epoch 48/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0077 - val_loss: 0.0078\n",
      "Epoch 49/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0077 - val_loss: 0.0065\n",
      "Epoch 50/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0081 - val_loss: 0.0101\n",
      "Epoch 51/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0078 - val_loss: 0.0073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johnny\\AppData\\Local\\Temp\\ipykernel_47812\\3948869189.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  evaluate['diff'] = evaluate['prediction']-evaluate['PM25']\n",
      "C:\\Users\\Johnny\\AppData\\Local\\Temp\\ipykernel_47812\\3948869189.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  evaluate['diff'] = evaluate['diff'].abs();\n",
      "C:\\Users\\Johnny\\AppData\\Local\\Temp\\ipykernel_47812\\3948869189.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  evaluate['mape'] = evaluate['diff']/evaluate['PM25'];\n",
      "C:\\Users\\Johnny\\AppData\\Local\\Temp\\ipykernel_47812\\3948869189.py:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  evaluate['mape']=abs((evaluate['PM25']-evaluate['prediction'])/evaluate['PM25'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE 28079022 - 75.98921595946678\n",
      "MAE 28079022 - 0.08998482603307738\n",
      "MSE 28079022 - 0.016463057212724824\n",
      "RMSE 28079022 - 0.12830844560170163\n",
      "duration 28079022 36.793288469314575\n",
      "Total data size: 17520\n",
      "Train data size: 10512\n",
      "Valid data size: 3504\n",
      "Test data size: 3504\n",
      "Model: \"sequential_198\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_232 (GRU)                (None, 300)               272700    \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (None, 24)                7224      \n",
      "=================================================================\n",
      "Total params: 279,924\n",
      "Trainable params: 279,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "146/146 [==============================] - 2s 6ms/step - loss: 0.0074 - val_loss: 0.0049\n",
      "Epoch 2/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 3/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 4/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 5/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0041 - val_loss: 0.0067\n",
      "Epoch 6/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0038 - val_loss: 0.0077\n",
      "Epoch 7/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0036 - val_loss: 0.0083\n",
      "Epoch 8/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0032 - val_loss: 0.0096\n",
      "Epoch 9/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0031 - val_loss: 0.0101\n",
      "Epoch 10/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0030 - val_loss: 0.0113\n",
      "Epoch 11/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0028 - val_loss: 0.0109\n",
      "Epoch 12/100\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0028 - val_loss: 0.0126\n",
      "Epoch 13/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0027 - val_loss: 0.0117\n",
      "Epoch 14/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0027 - val_loss: 0.0102\n",
      "Epoch 15/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0026 - val_loss: 0.0130\n",
      "Epoch 16/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0025 - val_loss: 0.0123\n",
      "Epoch 17/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0026 - val_loss: 0.0100\n",
      "Epoch 18/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0026 - val_loss: 0.0134\n",
      "Epoch 19/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0026 - val_loss: 0.0137\n",
      "Epoch 20/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0025 - val_loss: 0.0122\n",
      "Epoch 21/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0025 - val_loss: 0.0130\n",
      "Epoch 22/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0024 - val_loss: 0.0131\n",
      "Epoch 23/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0025 - val_loss: 0.0131\n",
      "Epoch 24/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0025 - val_loss: 0.0113\n",
      "Epoch 25/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0024 - val_loss: 0.0105\n",
      "Epoch 26/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0024 - val_loss: 0.0162\n",
      "Epoch 27/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0025 - val_loss: 0.0118\n",
      "Epoch 28/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0025 - val_loss: 0.0129\n",
      "Epoch 29/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0025 - val_loss: 0.0136\n",
      "Epoch 30/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0024 - val_loss: 0.0131\n",
      "Epoch 31/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0024 - val_loss: 0.0104\n",
      "Epoch 32/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0024 - val_loss: 0.0115\n",
      "Epoch 33/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0025 - val_loss: 0.0141\n",
      "Epoch 34/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0024 - val_loss: 0.0130\n",
      "Epoch 35/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0024 - val_loss: 0.0119\n",
      "Epoch 36/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0025 - val_loss: 0.0111\n",
      "Epoch 37/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0024 - val_loss: 0.0116\n",
      "Epoch 38/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0024 - val_loss: 0.0106\n",
      "Epoch 39/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0024 - val_loss: 0.0122\n",
      "Epoch 40/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0023 - val_loss: 0.0121\n",
      "Epoch 41/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0024 - val_loss: 0.0120\n",
      "Epoch 42/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0024 - val_loss: 0.0127\n",
      "Epoch 43/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0024 - val_loss: 0.0132\n",
      "Epoch 44/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0024 - val_loss: 0.0123\n",
      "Epoch 45/100\n",
      "146/146 [==============================] - 1s 5ms/step - loss: 0.0024 - val_loss: 0.0141\n",
      "Epoch 46/100\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.0024 - val_loss: 0.0120\n",
      "Epoch 47/100\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.0024 - val_loss: 0.0120\n",
      "Epoch 48/100\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.0024 - val_loss: 0.0113\n",
      "Epoch 49/100\n",
      "146/146 [==============================] - 1s 6ms/step - loss: 0.0024 - val_loss: 0.0111\n",
      "Epoch 50/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0024 - val_loss: 0.0123\n",
      "Epoch 51/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0023 - val_loss: 0.0120\n",
      "Epoch 52/100\n",
      "146/146 [==============================] - 1s 4ms/step - loss: 0.0024 - val_loss: 0.0145\n",
      "MAPE 28079015 - 19.48141567554351\n",
      "MAE 28079015 - 0.05637720764179069\n",
      "MSE 28079015 - 0.005641044259511483\n",
      "RMSE 28079015 - 0.07510688556658093\n",
      "duration 28079015 36.791253328323364\n",
      "Overall MAPE: 47.63176964272168\n",
      "Overall accuracy: 52.36823035727832\n",
      "Overall MAE: 0.060201028641992005\n",
      "Overall MSE: 0.007551422162832504\n",
      "Overall RMSE: 0.08458330464296844\n",
      "Overall duration: 38.26584780216217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Johnny\\AppData\\Local\\Temp\\ipykernel_47812\\3948869189.py:198: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  evaluate['diff'] = evaluate['prediction']-evaluate['PM25']\n",
      "C:\\Users\\Johnny\\AppData\\Local\\Temp\\ipykernel_47812\\3948869189.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  evaluate['diff'] = evaluate['diff'].abs();\n",
      "C:\\Users\\Johnny\\AppData\\Local\\Temp\\ipykernel_47812\\3948869189.py:200: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  evaluate['mape'] = evaluate['diff']/evaluate['PM25'];\n",
      "C:\\Users\\Johnny\\AppData\\Local\\Temp\\ipykernel_47812\\3948869189.py:204: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  evaluate['mape']=abs((evaluate['PM25']-evaluate['prediction'])/evaluate['PM25'])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from pandas import Series\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from math import sqrt\n",
    "from datetime import datetime,timedelta\n",
    "from dateutil.rrule import rrule, HOURLY\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import itertools\n",
    "import math\n",
    "import time\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import GRU, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def percentage_error(actual, predicted):\n",
    "    res = np.empty(actual.shape)\n",
    "    for j in range(actual.shape[0]):\n",
    "        if actual[j] != 0:\n",
    "            res[j] = (actual[j] - predicted[j]) / actual[j]\n",
    "        else:\n",
    "            res[j] = predicted[j] / np.mean(actual)\n",
    "    return res    \n",
    "\n",
    "def mae(actual, predicted):\n",
    "    res = np.empty(actual.shape)\n",
    "    r = 0\n",
    "    n = 0\n",
    "    for j in range(actual.shape[0]):\n",
    "            r += abs(actual[j] - predicted[j])\n",
    "            n+=1\n",
    "    return r/n    \n",
    "\n",
    "def mse(actual, predicted):\n",
    "    res = np.empty(actual.shape)\n",
    "    r = 0\n",
    "    n=0\n",
    "    for j in range(actual.shape[0]):\n",
    "            r += (actual[j] - predicted[j])**2\n",
    "            n+=1\n",
    "    return r/n    \n",
    "\n",
    "def rmse (actual, predicted):\n",
    "    r = mse(actual,predicted)\n",
    "    return math.sqrt(r)\n",
    "\n",
    "totalmae=0\n",
    "totalmse=0\n",
    "totalrmse=0\n",
    "totalduration=0\n",
    "\n",
    "frames=[]\n",
    "totalmape=0\n",
    "no_predictions = 24\n",
    "lag = 6\n",
    "batch_size=72\n",
    "epochs = 100\n",
    "patience = 50\n",
    "\n",
    "#ids = [28079024, 28079038, 28079008, 28079040, 28079036, 28079018, 28079011, 28079004, 28079016, 28079039, 28079027]\n",
    "#ids = [28079024, 28079038, 28079008, 28079047, 28079050, 28079048, 28079099, 28079026, 28079006, 28079022, 28079001, 28079015]\n",
    "ids = [28079008, 28079047, 28079026, 28079006, 28079022, 28079015]\n",
    "for k in ids:\n",
    "    start_exec = time.time()\n",
    "    dffinal=pd.read_csv(\"processed-\"+str(k)+\".csv\", index_col='date',parse_dates=True)\n",
    "    #dffinal=pd.read_csv(\"cleaned.csv\", index_col='date',parse_dates=True)\n",
    "\n",
    "    dffinal=dffinal.drop(columns=['NO','CH4','BEN','CO','EBE','MXY','NMHC','O_3','NOx','OXY','PM10','PXY','SO_2','TCH','TOL','NO_2','station'])\n",
    "    dffinal.dropna()\n",
    "    dffinal.drop(dffinal.index[365*24*2:],inplace=True)\n",
    "\n",
    "\n",
    "    sc_in = MinMaxScaler(feature_range=(0, 1))\n",
    "    dffinal['PM25'] = sc_in.fit_transform(dffinal[['PM25']])\n",
    "    \n",
    "    #split data\n",
    "    train_size=  int(len(dffinal) *0.6)\n",
    "    valid_size = (int)((int(len(dffinal)) - train_size)/2)\n",
    "    test_size = (int(len(dffinal)) - train_size-valid_size)\n",
    "\n",
    "    train = dffinal[:train_size].dropna()\n",
    "    valid = dffinal[train_size:train_size+valid_size].dropna()\n",
    "    test = dffinal[train_size+valid_size:].dropna()\n",
    "\n",
    "    print(\"Total data size:\",len(dffinal))\n",
    "    print(\"Train data size:\",len(train))\n",
    "    print(\"Valid data size:\",len(valid))\n",
    "    print(\"Test data size:\",len(test))\n",
    "    \n",
    "\n",
    "    train_shifted = train.copy();\n",
    "    valid_shifted = valid.copy();\n",
    "    test_shifted = test.copy();\n",
    "    train_shifted['y_t+1'] = train_shifted['PM25'].shift(-1, freq='H')\n",
    "    valid_shifted['y_t+1'] = valid_shifted['PM25'].shift(-1, freq='H')\n",
    "    test_shifted['y_t+1'] = test_shifted['PM25'].shift(-1, freq='H')\n",
    "    for t in range(1,lag+1):\n",
    "        train_shifted[str(lag-t)] = train_shifted['PM25'].shift(lag-t, freq='H')\n",
    "        valid_shifted[str(lag-t)] = valid_shifted['PM25'].shift(lag-t, freq='H')\n",
    "        test_shifted[str(lag-t)] = test_shifted['PM25'].shift(lag-t, freq='H')\n",
    "    y_col = 'y_t+1';\n",
    "    X_cols = []\n",
    "    for i in range(1,lag):\n",
    "        X_cols.append('PM25_t-'+str(lag-i))\n",
    "    X_cols.append('PM25_t')\n",
    "    \n",
    "    train_shifted.columns=['PM25']+[y_col]+X_cols\n",
    "    train_shifted.dropna(how='any', inplace=True)\n",
    "    valid_shifted.columns=['PM25']+[y_col]+X_cols\n",
    "    valid_shifted.dropna(how='any', inplace=True)\n",
    "    test_shifted.columns=['PM25']+[y_col]+X_cols\n",
    "    test_shifted.dropna(how='any', inplace=True)\n",
    "\n",
    "   \n",
    "    y_train = train_shifted[y_col].values\n",
    "    X_train = train_shifted[X_cols].values \n",
    "    X_train = X_train.reshape(X_train.shape[0],lag, 1)\n",
    "\n",
    "    y_valid = valid_shifted[y_col].values\n",
    "    X_valid = valid_shifted[X_cols].values \n",
    "    X_valid = X_valid.reshape(X_valid.shape[0],lag, 1)\n",
    "\n",
    "    y_test = test_shifted[y_col].values\n",
    "    X_test = test_shifted[X_cols].values \n",
    "    X_test = X_test.reshape(X_test.shape[0],lag, 1)\n",
    "    \n",
    "    #fit best model\n",
    "    #model = Sequential();\n",
    "    #model.add(GRU(lag, input_shape=(lag,1)))\n",
    "    #model.add(Dense(no_predictions))\n",
    "    #model.compile(optimizer='RMSprop', loss='mse')\n",
    "    #model.summary()\n",
    "    \n",
    "    model = Sequential();\n",
    "    model.add(GRU(300, dropout=0.5, input_shape=(lag,1)))\n",
    "    model.add(Dense(units = no_predictions)) \n",
    "    #Compile model\n",
    "    model.compile(optimizer='adam',loss='mse')\n",
    "    model.summary();\n",
    "    \n",
    "    #model = Sequential();\n",
    "    #model.add(GRU(lag, input_shape=(lag, 1)))\n",
    "    #model.add(Dense(units = 24*24*100, activation = 'relu'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    #model.add(Dense(units = 24, activation = 'linear'))\n",
    "    #model.compile(loss='mean_squared_error', optimizer=RMSprop(lr = 0.00001))\n",
    "    #model.summary()\n",
    "    \n",
    "    #model = Sequential()\n",
    "    # First GRU layer with Dropout regularisation\n",
    "    #model.add(GRU(units=120, return_sequences=True, input_shape=(lag,1), activation='tanh'))\n",
    "    #model.add(Dropout(0.9))\n",
    "    # Second GRU layer\n",
    "    #model.add(GRU(units=120, return_sequences=True, input_shape=(lag,1), activation='tanh'))\n",
    "    #model.add(Dropout(0.9))\n",
    "    # Third GRU layer\n",
    "    #model.add(GRU(units=120, return_sequences=True, input_shape=(lag,1), activation='tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    # Fourth GRU layer\n",
    "    #model.add(GRU(units=lag, activation='tanh'))\n",
    "    #model.add(Dropout(0.9))\n",
    "    # The output layer\n",
    "    #model.add(Dense(units=no_predictions))\n",
    "    #model.compile(loss='mean_squared_error', optimizer=RMSprop(lr = 0.00001))\n",
    "    #model.summary()\n",
    "    \n",
    "    early_stop = EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=patience, restore_best_weights=True)\n",
    "#    early_stop = EarlyStopping(monitor='val_loss', min_delta=0.00001, patience=patience)\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_valid, y_valid),callbacks=[early_stop], verbose=1)\n",
    "    #X_test = X_test[:1]\n",
    "    #print(X_test)\n",
    "    #print(test_shifted.head(24))\n",
    "    forecast = model.predict(X_test)\n",
    "    #print(\"Forecast\",no_predictions,\":\")\n",
    "    #print(forecast)\n",
    "\n",
    "    evaluate = pd.DataFrame(forecast, columns=['t+'+str(i) for i in range(1,no_predictions+1)])\n",
    "    evaluate['timestamp'] = test_shifted.index\n",
    "    evaluate = pd.melt(evaluate, id_vars='timestamp',value_name='prediction', var_name='h')\n",
    "    evaluate[['ht','hh']]=evaluate['h'].str.split('+',1, expand=True)\n",
    "    evaluate['hh'] = pd.to_numeric(evaluate['hh'])\n",
    "    evaluate['hh'] = pd.to_timedelta(evaluate['hh'], unit='h')\n",
    "    evaluate['ts']=evaluate['timestamp']+evaluate['hh']\n",
    "    mg = evaluate.merge(test_shifted, how='inner', left_on='ts', right_on='date')\n",
    "    evaluate=mg[['timestamp','ts','h','prediction','PM25']];\n",
    "    evaluate['diff'] = evaluate['prediction']-evaluate['PM25']\n",
    "    evaluate['diff'] = evaluate['diff'].abs();\n",
    "    evaluate['mape'] = evaluate['diff']/evaluate['PM25'];\n",
    "    tmape = evaluate['mape'].sum()/evaluate['mape'].count();\n",
    "    #print(\"TOTAL MAPE:\",tmape)\n",
    "    #print(evaluate)\n",
    "    evaluate['mape']=abs((evaluate['PM25']-evaluate['prediction'])/evaluate['PM25'])\n",
    "    vmape = np.mean(np.abs(percentage_error(np.asarray(evaluate['PM25']), np.asarray(evaluate['prediction'])))) * 100\n",
    "    vmae = mae(np.asarray(evaluate['PM25']), np.asarray(evaluate['prediction']))\n",
    "    vmse = mse(np.asarray(evaluate['PM25']), np.asarray(evaluate['prediction']))\n",
    "    vrmse = rmse(np.asarray(evaluate['PM25']), np.asarray(evaluate['prediction']))\n",
    "    end_exec = time.time()\n",
    "    duration = end_exec-start_exec\n",
    "    print(\"MAPE\",k,'-',vmape);\n",
    "    print(\"MAE\",k,'-',vmae);\n",
    "    print(\"MSE\",k,'-',vmse);\n",
    "    print(\"RMSE\",k,'-',vrmse);\n",
    "    print(\"duration\",k,duration)\n",
    "    totalmape += vmape\n",
    "    totalmae += vmae\n",
    "    totalmse += vmse\n",
    "    totalrmse += vrmse\n",
    "    totalduration += duration\n",
    "    #fig, ax = plt.subplots(1, 1)\n",
    "    #forecasts.plot(title=\"Forecasts\", ax=ax)\n",
    "#    forecasts.plot(kind='kde', title='Forecast', ax=ax[1])\n",
    "#    plt.show();\n",
    "\n",
    "#    predictions = model.predict(start=train_size, end=train_size+no_predictions-1)\n",
    "#    print(\"Type predictions:\",type(predictions))\n",
    "#    pred = pd.DataFrame(predictions)\n",
    "#    pred.index = list(pred.index)\n",
    "#    print(\"Index pred:\",pred.index)\n",
    "#    print(\"Index test:\",test_X.index)\n",
    "#    a = pred.loc[train_size]\n",
    "#    b = test_X.loc[train_size]\n",
    "#    print(\"A:\",a)\n",
    "#    print(\"B:\",b)\n",
    "#    print(\"Type pred:\",type(pred))\n",
    "#    print(\"Predictions:\")\n",
    "#    print(pred);\n",
    "#    tape = 0\n",
    "#    for i in range(train_size, train_size+no_predictions-1):\n",
    "#        ape = abs(pred.loc[i].predicted_mean-test_X.loc[i].PM25)/abs(test_X.loc[i].PM25)*100\n",
    "#        tape = tape + ape\n",
    "#    mape = tape/no_predictions;\n",
    "#    print(\"MAPE:\",mape)\n",
    "#    print(\"Accuracy:\",100.0-mape)\n",
    "#    totalmape = totalmape + mape\n",
    "overallmape = totalmape/len(ids)\n",
    "overallmae = totalmae/len(ids)\n",
    "overallmse = totalmse/len(ids)\n",
    "overallrmse = totalrmse/len(ids)\n",
    "overallduration = totalduration/len(ids)\n",
    "print(\"Overall MAPE:\",overallmape)\n",
    "print(\"Overall accuracy:\",100.0-overallmape)\n",
    "print(\"Overall MAE:\",overallmae)\n",
    "print(\"Overall MSE:\",overallmse)\n",
    "print(\"Overall RMSE:\",overallrmse)\n",
    "print(\"Overall duration:\",overallduration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
