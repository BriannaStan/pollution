{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          NO_2     station\n",
      "date                                      \n",
      "2001-01-01 01:00:00  59.150002  28079018.0\n",
      "2001-01-01 02:00:00  55.250000  28079018.0\n",
      "2001-01-01 03:00:00  54.740002  28079018.0\n",
      "2001-01-01 04:00:00  48.160000  28079018.0\n",
      "2001-01-01 05:00:00  43.700001  28079018.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from pandas import Series\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from math import sqrt\n",
    "from datetime import datetime,timedelta\n",
    "from dateutil.rrule import rrule, HOURLY\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "frames=[]\n",
    "dffinal=pd.read_csv(\"cleaned.csv\", index_col='date',parse_dates=True)\n",
    "\n",
    "dffinal=dffinal.drop(columns=['NO','CH4','BEN','CO','EBE','MXY','NMHC','NOx','OXY','O_3','PM10','PXY','SO_2','TCH','TOL','PM25'])\n",
    "\n",
    "print(dffinal.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_start_train = pd.Timestamp('2002-01-01')\n",
    "split_end_train = split_start_test = pd.Timestamp('2012-01-01')\n",
    "split_end_test= split_start_valid = pd.Timestamp('2013-01-01')\n",
    "split_end_valid = pd.Timestamp('2014-01-01');\n",
    "df_train = dffinal.loc[split_start_train:split_end_train]\n",
    "df_test = dffinal.loc[split_start_test:split_end_test]\n",
    "df_valid =  dffinal.loc[split_start_valid:split_end_valid]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           NO_2     station\n",
      "date                                       \n",
      "2002-01-01 00:00:00   90.430000  28079018.0\n",
      "2002-01-01 01:00:00   44.000000  28079018.0\n",
      "2002-01-01 02:00:00   44.000000  28079018.0\n",
      "2002-01-01 03:00:00  107.300003  28079018.0\n",
      "2002-01-01 04:00:00   82.419998  28079018.0\n"
     ]
    }
   ],
   "source": [
    "# Define the p, d and q parameters to take any value between 0 and 2\n",
    "import itertools\n",
    "p = d = q = range(0, 2)\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "pdqs = [(x[0], x[1], x[2], 12) for x in list(itertools.product(p, d, q))]\n",
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determine what the best model would be using a for loop\n",
    "ans = []\n",
    "for comb in pdq:\n",
    "    for combs in pdqs:\n",
    "        try:\n",
    "            mod = sm.tsa.statespace.SARIMAX(df_train,\n",
    "                                            order=comb,\n",
    "                                            seasonal_order=combs,\n",
    "                                            enforce_stationarity=False,\n",
    "                                            enforce_invertibility=False)\n",
    "\n",
    "            output = mod.fit()\n",
    "            ans.append([comb, combs, output.aic])\n",
    "            print('ARIMA {} x {}12 : AIC Calculated ={}'.format(comb, combs, output.aic))\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "reduction operation 'argmin' not allowed for this dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-cfcf086c882f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#print out the best model parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mans_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'pdq'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'pdqs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'aic'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mans_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mans_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'aic'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midxmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36midxmin\u001b[1;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2101\u001b[0m         \"\"\"\n\u001b[0;32m   2102\u001b[0m         \u001b[0mskipna\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_argmin_with_skipna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2103\u001b[1;33m         \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnanops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnanargmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2104\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2105\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mobj_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mf_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nan\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m                 raise TypeError(\n\u001b[0m\u001b[0;32m     69\u001b[0m                     \u001b[1;34mf\"reduction operation '{f_name}' not allowed for this dtype\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                 )\n",
      "\u001b[1;31mTypeError\u001b[0m: reduction operation 'argmin' not allowed for this dtype"
     ]
    }
   ],
   "source": [
    "#print out the best model parameters\n",
    "ans_df = pd.DataFrame(ans, columns=['pdq', 'pdqs', 'aic'])\n",
    "print(ans_df.loc[ans_df['aic'].idxmin()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "SARIMAX models require univariate `endog`. Got shape (86617, 2).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-a1925dc8df34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Use pdq and pdqs above to fit the data with the ARIMA model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m ARIMA_MODEL = sm.tsa.statespace.SARIMAX(df_train,\n\u001b[0m\u001b[0;32m      3\u001b[0m                                 \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                 \u001b[0mseasonal_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                 \u001b[0menforce_stationarity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, order, seasonal_order, trend, measurement_error, time_varying_regression, mle_regression, simple_differencing, enforce_stationarity, enforce_invertibility, hamilton_representation, concentrate_scale, trend_offset, use_exact_diffuse, dates, freq, missing, validate_specification, **kwargs)\u001b[0m\n\u001b[0;32m    326\u001b[0m                  **kwargs):\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m         self._spec = SARIMAXSpecification(\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[0mendog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseasonal_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseasonal_order\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[0mtrend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menforce_stationarity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menforce_invertibility\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tsa\\arima\\specification.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, endog, exog, order, seasonal_order, ar_order, diff, ma_order, seasonal_ar_order, seasonal_diff, seasonal_ma_order, seasonal_periods, trend, enforce_stationarity, enforce_invertibility, concentrate_scale, trend_offset, dates, freq, missing, validate_specification)\u001b[0m\n\u001b[0;32m    452\u001b[0m         if (validate_specification and not faux_endog and\n\u001b[0;32m    453\u001b[0m                 self.endog.ndim > 1 and self.endog.shape[1] > 1):\n\u001b[1;32m--> 454\u001b[1;33m             raise ValueError('SARIMAX models require univariate `endog`. Got'\n\u001b[0m\u001b[0;32m    455\u001b[0m                              ' shape %s.' % str(self.endog.shape))\n\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: SARIMAX models require univariate `endog`. Got shape (86617, 2)."
     ]
    }
   ],
   "source": [
    "#Use pdq and pdqs above to fit the data with the ARIMA model\n",
    "ARIMA_MODEL = sm.tsa.statespace.SARIMAX(df_train,\n",
    "                                order=(1, 0, 1),\n",
    "                                seasonal_order=(0, 1, 1, 12),\n",
    "                                enforce_stationarity=False,\n",
    "                                enforce_invertibility=False)\n",
    "\n",
    "output_df_train = ARIMA_MODEL.fit()\n",
    "\n",
    "print(output_df_train.summary().tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ddde73792621>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Use plot_diagnostics with results calculated above to make sure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#our assumptions of normality and correlation hold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0moutput_df_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_diagnostics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m18\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output_df_train' is not defined"
     ]
    }
   ],
   "source": [
    "#Use plot_diagnostics with results calculated above to make sure \n",
    "#our assumptions of normality and correlation hold\n",
    "output_df_train.plot_diagnostics(figsize=(15, 18))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
